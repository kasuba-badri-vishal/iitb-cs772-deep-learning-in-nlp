{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "afa00d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "\n",
    "text_counter = Counter()\n",
    "tqdm.pandas()\n",
    "mps_device = torch.device(\"mps\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8aab0c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_PATH = './../weights/'\n",
    "DATASET_PATH = './trainset.csv'\n",
    "INTERMEDIATE_PATH = './../intermediate/'\n",
    "RESULTS_PATH = './../results/'\n",
    "VALIDATION = './../data/Validation.txt'\n",
    "\n",
    "\n",
    "embedding_size = 512\n",
    "no_of_rows     = None\n",
    "window_size    = 3\n",
    "max_epochs     = 10000\n",
    "learning_rate  = 0.001\n",
    "reg_lambda     = 1\n",
    "batch_size     = 8192\n",
    "train_split    = 0.8\n",
    "is_train       = True\n",
    "new_weights    = True\n",
    "use_biases     = False\n",
    "problem        = 'skipgram'\n",
    "\n",
    "epochs_stat = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "12914f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.y_pred = None\n",
    "        self.emb    = None\n",
    "\n",
    "        if(os.path.exists(WEIGHTS_PATH + 'skipgram_weights_' + str(vocab_size) + '.pt') and (new_weights == False)):\n",
    "            self.weights = torch.load(WEIGHTS_PATH + 'skipgram_weights_' + str(vocab_size) + '.pt')\n",
    "            self.biases = torch.load(WEIGHTS_PATH + 'skipgram_biases_' + str(vocab_size) + '.pt')\n",
    "        else:\n",
    "            self.weights = []\n",
    "            self.biases  = []\n",
    "            \n",
    "            self.weights.append(torch.rand((vocab_size, embedding_size), device=mps_device) * 2 - 1)\n",
    "            self.weights.append(torch.rand((embedding_size, vocab_size), device=mps_device) * 2 - 1)\n",
    "            if(use_biases):\n",
    "                self.biases.append(torch.rand((embedding_size), device=mps_device) * 2 - 1)\n",
    "                self.biases.append(torch.rand((vocab_size), device=mps_device) * 2 - 1)\n",
    "            else:\n",
    "                self.biases.append(torch.zeros((embedding_size), device=mps_device))\n",
    "                self.biases.append(torch.zeros((vocab_size), device=mps_device))\n",
    "\n",
    "    def __call__(self, X):\n",
    "        self.emb = (torch.matmul(X,self.weights[0]) + self.biases[0])\n",
    "        self.y_pred = torch.softmax(torch.matmul(self.emb, self.weights[1]) + self.biases[1], dim=1)\n",
    "        return self.y_pred\n",
    "\n",
    "    def backward(self, X, y, lamda):\n",
    "        \n",
    "        del_W = []\n",
    "        del_b = []\n",
    "\n",
    "        delta = self.y_pred - y\n",
    "        del_b.insert(0,torch.sum(delta, axis = 0, keepdims = True))\n",
    "        del_W.insert(0,torch.matmul(self.emb.T, delta) + lamda * (self.weights[1]))\n",
    "\n",
    "        delta = torch.matmul(delta, self.weights[1].T) * (self.emb)\n",
    "        del_b.insert(0,torch.sum(delta, axis = 0, keepdims = True))\n",
    "        del_W.insert(0,torch.matmul(X.T, delta) + lamda * (self.weights[0]))\n",
    "        return del_W, del_b\n",
    "\n",
    "    \n",
    "class Optimizer(object):\n",
    "    '''\n",
    "    '''\n",
    "    def __init__(self, learning_rate, weights, biases, optimizer=\"gradient\"):\n",
    "        \n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        self.m_dw = [torch.zeros((w.shape), device=mps_device) for w in weights]\n",
    "        self.m_db = [torch.zeros((b.shape), device=mps_device) for b in biases]\n",
    "        self.v_dw = [torch.zeros((w.shape), device=mps_device) for w in weights]\n",
    "        self.v_db = [torch.zeros((b.shape), device=mps_device) for b in biases]\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "        self.epsilon = 1e-8\n",
    "        self.eta = learning_rate\n",
    "        self.t = 0\n",
    "\n",
    "    def step(self, weights, biases, delta_weights, delta_biases):\n",
    "        \n",
    "        if(self.optimizer == \"gradient\"):\n",
    "            return self.gradient(weights, biases, delta_weights, delta_biases)\n",
    "        elif(self.optimizer == \"adam\"):\n",
    "            return self.adam(weights, biases, delta_weights, delta_biases)\n",
    "    \n",
    "    def adam(self, weights, biases, delta_weights, delta_biases):\n",
    "        self.t += 1\n",
    "\n",
    "        self.m_dw = [self.beta1 * m + (1 - self.beta1) * del_w for m, del_w in zip(self.m_dw, delta_weights)]\n",
    "        self.m_db = [self.beta1 * m + (1 - self.beta1) * del_b for m, del_b in zip(self.m_db, delta_biases)]\n",
    "        self.v_dw = [self.beta2 * v + (1 - self.beta2) * (del_w**2) for v, del_w in zip(self.v_dw, delta_weights)]\n",
    "        self.v_db = [self.beta2 * v + (1 - self.beta2) * (del_b**2) for v, del_b in zip(self.v_db, delta_biases)]\n",
    "\n",
    "        # bias correction\n",
    "        m_hat_dw = [m / (1 - self.beta1 ** self.t) for m in self.m_dw]\n",
    "        v_hat_dw = [v / (1 - self.beta2 ** self.t) for v in self.v_dw]\n",
    "\n",
    "        m_hat_db = [m / (1 - self.beta1 ** self.t) for m in self.m_db]\n",
    "        v_hat_db = [v / (1 - self.beta2 ** self.t) for v in self.v_db]\n",
    "\n",
    "        # update weights and biases\n",
    "        weights = [w - self.eta * m_hat / ((torch.sqrt(v_hat) + self.epsilon)) for w, m_hat, v_hat in zip(weights, m_hat_dw, v_hat_dw)] \n",
    "        biases = [b - self.eta * m_hat / ((torch.sqrt(v_hat) + self.epsilon)) for b, m_hat, v_hat in zip(biases, m_hat_db, v_hat_db)]\n",
    "        return weights, biases\n",
    "\n",
    "    \n",
    "    def gradient(self, weights, biases, delta_weights, delta_biases):\n",
    "        for i in range(len(weights)):\n",
    "            weights[i] = weights[i] - self.eta*delta_weights[i]\n",
    "            biases[i] = biases[i] - self.eta*delta_biases[i]\n",
    "        return weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "56270eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(word):\n",
    "    try:\n",
    "        val = word2idx[word]\n",
    "        input_arr = torch.zeros((vocab_size), dtype=torch.float, device=mps_device)\n",
    "        input_arr[val] = 1\n",
    "        emb = torch.matmul(input_arr,net.weights[0]) + net.biases[0]\n",
    "        return emb\n",
    "    except:\n",
    "        return torch.empty(0, dtype=torch.float, device=mps_device)\n",
    "\n",
    "def get_result(word1, word2, word3, problem='skipgram', window=4):\n",
    "    w1_emb = get_embeddings(word1)\n",
    "    w2_emb = get_embeddings(word2)    \n",
    "    w3_emb = get_embeddings(word3)    \n",
    "    if((torch.numel(w1_emb) != 0) and (torch.numel(w2_emb) != 0) and (torch.numel(w3_emb) != 0)):\n",
    "        w4_emb = w1_emb + w3_emb - w2_emb\n",
    "        output = torch.softmax(torch.matmul(w4_emb, net.weights[1]) + net.biases[1], dim=1)\n",
    "        if(problem=='skipgram'):\n",
    "            topk_preds = torch.topk(output, k=window).indices.tolist()\n",
    "            ans = [idx2word[x] for x in topk_preds[0]]\n",
    "        else:\n",
    "            ans = idx2word[torch.argmax(output).item()]\n",
    "        return ans\n",
    "    return \"UNK\"\n",
    "\n",
    "\n",
    "def get_embeddings(word):\n",
    "    try:\n",
    "        val = word2idx[word]\n",
    "        input_arr = torch.zeros((vocab_size), dtype=torch.float, device=mps_device)\n",
    "        input_arr[val] = 1\n",
    "        emb = torch.matmul(input_arr,net.weights[0]) + net.biases[0]\n",
    "        return emb\n",
    "    except:\n",
    "        return torch.empty(0, dtype=torch.float, device=mps_device)\n",
    "    \n",
    "def get_accuracy(validation):\n",
    "    accuracy = torch.empty(0, dtype=torch.float, device=mps_device)\n",
    "    for _, row in validation.iterrows():\n",
    "        w1_emb = get_embeddings(row['word1'])\n",
    "        w2_emb = get_embeddings(row['word2'])    \n",
    "        w3_emb = get_embeddings(row['word3'])\n",
    "        w4_emb = get_embeddings(row['word4'])\n",
    "        \n",
    "        if((torch.numel(w1_emb) != 0) and (torch.numel(w2_emb) != 0) and (torch.numel(w3_emb) != 0)):\n",
    "            pred_emb = w1_emb + w3_emb - w2_emb\n",
    "            accuracy = torch.cat(accuracy, cosine_similarity(pred_emb, w4_emb), dim=0)\n",
    "    return torch.mean(accuracy, dim=0)\n",
    "\n",
    "def cosine_similarity(A, B):\n",
    "    C = torch.squeeze(A)\n",
    "    D = torch.squeeze(B)\n",
    "    return torch.dot(C, D) / (torch.norm(C) * torch.norm(D))\n",
    "\n",
    "def cross_entropy_loss(y_pred, y_true):\n",
    "    if(mps_device.type == 'mps'):\n",
    "        return -torch.mean(custom_nansum(y_true * torch.log(y_pred), axis=-1))\n",
    "    else:\n",
    "        return -torch.mean(torch.nansum(y_true * torch.log(y_pred), axis=-1))\n",
    "\n",
    "def get_dataset(words, window_size):\n",
    "    data = pd.DataFrame(columns=[\"word\", \"context_words\"])\n",
    "    for index, word in enumerate(words):\n",
    "        context_words = words[max(0, index - window_size): index] + words[index + 1: index + window_size + 1]\n",
    "        context_words = list(set(context_words))\n",
    "        data.loc[len(data.index)] = [word, context_words]\n",
    "    global dataset\n",
    "    dataset = pd.concat([dataset,data])\n",
    "    \n",
    "def custom_nansum(input_tensor, axis=None):\n",
    "    # Replace NaN values with 0\n",
    "    input_tensor = torch.where(torch.isnan(input_tensor), torch.tensor(0., device=input_tensor.device), input_tensor)\n",
    "    \n",
    "    # Compute the sum over the specified axis\n",
    "    if axis is None:\n",
    "        return torch.sum(input_tensor)\n",
    "    else:\n",
    "        return torch.sum(input_tensor, dim=axis)\n",
    "    \n",
    "    \n",
    "def get_batch_data(start_index, end_index):\n",
    "\n",
    "    batch_dataset = dataset[start_index:end_index].reset_index(drop=True)\n",
    "    batch_size = batch_dataset.shape[0]\n",
    "    batch_input = torch.zeros([batch_size, vocab_size], dtype=torch.float, device=mps_device)\n",
    "    batch_output = torch.zeros([batch_size, vocab_size], dtype=torch.float, device=mps_device)\n",
    "\n",
    "    for index, data in batch_dataset.iterrows():\n",
    "        batch_input[index, data['word']] = 1\n",
    "        for ind in data['context_words']:\n",
    "            batch_output[index, ind] = 1\n",
    "            \n",
    "    return batch_input, batch_output\n",
    "\n",
    "\n",
    "def train(net, optimizer, lamda, max_epochs, dev_input, dev_target, batch_size, train_size):\n",
    "\n",
    "    stop = False\n",
    "    value = 999999999\n",
    "    \n",
    "    for e in range(max_epochs):\n",
    "        first_loss = True\n",
    "        epoch = {}\n",
    "        batches = []\n",
    "        losses = []\n",
    "        for start_index in range(0, train_size, batch_size):\n",
    "            end_index = min(start_index + batch_size, train_size)\n",
    "            batch_input, batch_target = get_batch_data(start_index, end_index)\n",
    "            pred = net(batch_input)\n",
    "\n",
    "            # Compute gradients of loss w.r.t. weights and biases\n",
    "            dW, db = net.backward(batch_input, batch_target, lamda)\n",
    "\n",
    "            # Get updated weights based on current weights and gradients\n",
    "            weights_updated, biases_updated = optimizer.step(net.weights, net.biases, dW, db)\n",
    "\n",
    "            # Update model's weights and biases\n",
    "            net.weights = weights_updated\n",
    "            net.biases = biases_updated\n",
    "            loss = cross_entropy_loss(pred, batch_target)\n",
    "            print(e, start_index, loss.item())\n",
    "            batches.append(start_index)\n",
    "            losses.append(loss.item())\n",
    "            if(torch.isnan(loss) or torch.isinf(loss)):\n",
    "                stop = True\n",
    "                break\n",
    "\n",
    "            if(first_loss):\n",
    "                first_loss = False\n",
    "                if(value<loss.item()):\n",
    "                    stop = True\n",
    "                    break\n",
    "                else:\n",
    "                    value = loss.item()\n",
    "\n",
    "        epoch['batches'] = batches\n",
    "        epoch['losses'] = losses\n",
    "            \n",
    "\n",
    "        dev_pred = net(dev_input)\n",
    "        indices = torch.topk(dev_pred, k=window_size, dim=1)[1][:, -window_size:]\n",
    "        converted_matrix = torch.zeros_like(dev_pred)\n",
    "        converted_matrix[torch.arange(dev_pred.shape[0])[:, None], indices] = 1\n",
    "        numpy_dev_target = dev_target.cpu().numpy()\n",
    "        converted_matrix = converted_matrix.cpu().numpy()\n",
    "        score = f1_score(numpy_dev_target, converted_matrix, average='micro')\n",
    "        print('F1 Score on dev data: {:.5f}'.format(score))\n",
    "        epoch['f1_score'] = score\n",
    "        epochs_stat.append(epoch)\n",
    "        if(stop):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ec17f0",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5f657279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 425/425 [00:00<00:00, 777.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab length : 5009\n",
      "Dataset size : 1223334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET_PATH ,nrows = no_of_rows)\n",
    "df = df.dropna()\n",
    "\n",
    "df['sentences'] = df['sentences'].apply(lambda sentence : sentence.split())\n",
    "_ = df['sentences'].apply(text_counter.update)\n",
    "text_counter.update(['UNK'])\n",
    "vocab_size = len(text_counter)\n",
    "\n",
    "words, _ = zip(*text_counter.most_common(vocab_size))\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "idx2word = {i: w for i, w in enumerate(words)}\n",
    "\n",
    "\n",
    "# dataset = pd.read_pickle('dataset.pkl')\n",
    "df['sentences'] = df['sentences'].apply(lambda words : [word2idx[word] for word in words])\n",
    "\n",
    "# if(no_of_rows==None and os.path.exists(INTERMEDIATE_PATH + 'dataset.pkl')):\n",
    "#    dataset = pd.read_pickle(INTERMEDIATE_PATH + 'dataset.pkl') \n",
    "\n",
    "# elif(os.path.exists(INTERMEDIATE_PATH + 'dataset_'+str(no_of_rows)+'.pkl')):\n",
    "#     dataset = pd.read_pickle(INTERMEDIATE_PATH + 'dataset_'+str(no_of_rows)+'.pkl')\n",
    "# else:\n",
    "dataset = pd.DataFrame(columns=[\"word\", \"context_words\"])\n",
    "_ = df['sentences'].progress_apply(lambda x : get_dataset(x, window_size))\n",
    "\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "if(no_of_rows==None):\n",
    "    dataset.to_pickle(INTERMEDIATE_PATH + 'dataset.pkl') \n",
    "else:\n",
    "    dataset.to_pickle(INTERMEDIATE_PATH + 'dataset_'+str(no_of_rows)+'.pkl')\n",
    "\n",
    "data_size = dataset.shape[0]\n",
    "\n",
    "print(\"Vocab length :\", vocab_size)\n",
    "print(\"Dataset size :\", data_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990a02f8",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "061fde1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = max(int(train_split*data_size), data_size-5000)\n",
    "\n",
    "net = Net()\n",
    "optimizer = Optimizer(learning_rate, net.weights, net.biases, optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "88fbf234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 47.576759338378906\n",
      "F1 Score on dev data: 0.00627\n",
      "1 0 47.09143829345703\n",
      "F1 Score on dev data: 0.00627\n",
      "2 0 46.61103820800781\n",
      "F1 Score on dev data: 0.00627\n",
      "3 0 46.13486862182617\n",
      "F1 Score on dev data: 0.00627\n",
      "4 0 45.663150787353516\n",
      "F1 Score on dev data: 0.00627\n",
      "5 0 45.196102142333984\n",
      "F1 Score on dev data: 0.00627\n",
      "6 0 44.733863830566406\n",
      "F1 Score on dev data: 0.00627\n",
      "7 0 44.27666473388672\n",
      "F1 Score on dev data: 0.00627\n",
      "8 0 43.82476806640625\n",
      "F1 Score on dev data: 0.00627\n",
      "9 0 43.37847900390625\n",
      "F1 Score on dev data: 0.00627\n",
      "10 0 42.93806076049805\n",
      "F1 Score on dev data: 0.00627\n",
      "11 0 42.50373077392578\n",
      "F1 Score on dev data: 0.00627\n",
      "12 0 42.07563781738281\n",
      "F1 Score on dev data: 0.00627\n",
      "13 0 41.65381622314453\n",
      "F1 Score on dev data: 0.00627\n",
      "14 0 41.23833084106445\n",
      "F1 Score on dev data: 0.00627\n",
      "15 0 40.82908630371094\n",
      "F1 Score on dev data: 0.00627\n",
      "16 0 40.42593765258789\n",
      "F1 Score on dev data: 0.00627\n",
      "17 0 40.02873992919922\n",
      "F1 Score on dev data: 0.00627\n",
      "18 0 39.63747024536133\n",
      "F1 Score on dev data: 0.00627\n",
      "19 0 39.252105712890625\n",
      "F1 Score on dev data: 0.00627\n",
      "20 0 38.8726692199707\n",
      "F1 Score on dev data: 0.00627\n",
      "21 0 38.49924850463867\n",
      "F1 Score on dev data: 0.00784\n",
      "22 0 38.131988525390625\n",
      "F1 Score on dev data: 0.00784\n",
      "23 0 37.771080017089844\n",
      "F1 Score on dev data: 0.00627\n",
      "24 0 37.416690826416016\n",
      "F1 Score on dev data: 0.00627\n",
      "25 0 37.0689811706543\n",
      "F1 Score on dev data: 0.00627\n",
      "26 0 36.72804641723633\n",
      "F1 Score on dev data: 0.00627\n",
      "27 0 36.3939208984375\n",
      "F1 Score on dev data: 0.00627\n",
      "28 0 36.06657791137695\n",
      "F1 Score on dev data: 0.00627\n",
      "29 0 35.74592590332031\n",
      "F1 Score on dev data: 0.00627\n",
      "30 0 35.43178176879883\n",
      "F1 Score on dev data: 0.00627\n",
      "31 0 35.12396240234375\n",
      "F1 Score on dev data: 0.00627\n",
      "32 0 34.822269439697266\n",
      "F1 Score on dev data: 0.00627\n",
      "33 0 34.526573181152344\n",
      "F1 Score on dev data: 0.00627\n",
      "34 0 34.236759185791016\n",
      "F1 Score on dev data: 0.00784\n",
      "35 0 33.952720642089844\n",
      "F1 Score on dev data: 0.00784\n",
      "36 0 33.67431640625\n",
      "F1 Score on dev data: 0.00784\n",
      "37 0 33.40140151977539\n",
      "F1 Score on dev data: 0.00784\n",
      "38 0 33.13386154174805\n",
      "F1 Score on dev data: 0.00784\n",
      "39 0 32.871700286865234\n",
      "F1 Score on dev data: 0.00784\n",
      "40 0 32.615047454833984\n",
      "F1 Score on dev data: 0.00784\n",
      "41 0 32.36410903930664\n",
      "F1 Score on dev data: 0.00784\n",
      "42 0 32.11914825439453\n",
      "F1 Score on dev data: 0.00784\n",
      "43 0 31.880386352539062\n",
      "F1 Score on dev data: 0.00627\n",
      "44 0 31.64797592163086\n",
      "F1 Score on dev data: 0.00627\n",
      "45 0 31.421924591064453\n",
      "F1 Score on dev data: 0.00627\n",
      "46 0 31.202035903930664\n",
      "F1 Score on dev data: 0.00627\n",
      "47 0 30.987903594970703\n",
      "F1 Score on dev data: 0.00627\n",
      "48 0 30.77895736694336\n",
      "F1 Score on dev data: 0.00627\n",
      "49 0 30.574562072753906\n",
      "F1 Score on dev data: 0.00627\n",
      "50 0 30.3741512298584\n",
      "F1 Score on dev data: 0.00627\n",
      "51 0 30.177326202392578\n",
      "F1 Score on dev data: 0.00627\n",
      "52 0 29.983884811401367\n",
      "F1 Score on dev data: 0.00627\n",
      "53 0 29.793745040893555\n",
      "F1 Score on dev data: 0.00627\n",
      "54 0 29.60692024230957\n",
      "F1 Score on dev data: 0.00627\n",
      "55 0 29.423450469970703\n",
      "F1 Score on dev data: 0.00627\n",
      "56 0 29.243375778198242\n",
      "F1 Score on dev data: 0.00627\n",
      "57 0 29.066715240478516\n",
      "F1 Score on dev data: 0.00627\n",
      "58 0 28.893474578857422\n",
      "F1 Score on dev data: 0.00627\n",
      "59 0 28.723634719848633\n",
      "F1 Score on dev data: 0.00627\n",
      "60 0 28.557172775268555\n",
      "F1 Score on dev data: 0.00627\n",
      "61 0 28.394031524658203\n",
      "F1 Score on dev data: 0.00627\n",
      "62 0 28.234146118164062\n",
      "F1 Score on dev data: 0.00627\n",
      "63 0 28.077442169189453\n",
      "F1 Score on dev data: 0.00627\n",
      "64 0 27.923831939697266\n",
      "F1 Score on dev data: 0.00627\n",
      "65 0 27.773221969604492\n",
      "F1 Score on dev data: 0.00627\n",
      "66 0 27.625530242919922\n",
      "F1 Score on dev data: 0.00627\n",
      "67 0 27.48067283630371\n",
      "F1 Score on dev data: 0.00627\n",
      "68 0 27.338590621948242\n",
      "F1 Score on dev data: 0.00627\n",
      "69 0 27.199222564697266\n",
      "F1 Score on dev data: 0.00627\n",
      "70 0 27.06251335144043\n",
      "F1 Score on dev data: 0.00627\n",
      "71 0 26.928409576416016\n",
      "F1 Score on dev data: 0.00627\n",
      "72 0 26.79686164855957\n",
      "F1 Score on dev data: 0.00627\n",
      "73 0 26.667804718017578\n",
      "F1 Score on dev data: 0.00627\n",
      "74 0 26.54117202758789\n",
      "F1 Score on dev data: 0.00627\n",
      "75 0 26.416894912719727\n",
      "F1 Score on dev data: 0.00627\n",
      "76 0 26.294889450073242\n",
      "F1 Score on dev data: 0.00627\n",
      "77 0 26.175086975097656\n",
      "F1 Score on dev data: 0.00627\n",
      "78 0 26.05740737915039\n",
      "F1 Score on dev data: 0.00627\n",
      "79 0 25.94178009033203\n",
      "F1 Score on dev data: 0.00627\n",
      "80 0 25.8281307220459\n",
      "F1 Score on dev data: 0.00627\n",
      "81 0 25.716392517089844\n",
      "F1 Score on dev data: 0.00627\n",
      "82 0 25.606504440307617\n",
      "F1 Score on dev data: 0.00627\n",
      "83 0 25.498401641845703\n",
      "F1 Score on dev data: 0.00627\n",
      "84 0 25.392024993896484\n",
      "F1 Score on dev data: 0.00627\n",
      "85 0 25.287309646606445\n",
      "F1 Score on dev data: 0.00627\n",
      "86 0 25.184194564819336\n",
      "F1 Score on dev data: 0.00627\n",
      "87 0 25.082616806030273\n",
      "F1 Score on dev data: 0.00627\n",
      "88 0 24.982511520385742\n",
      "F1 Score on dev data: 0.00627\n",
      "89 0 24.883813858032227\n",
      "F1 Score on dev data: 0.00627\n",
      "90 0 24.786468505859375\n",
      "F1 Score on dev data: 0.00627\n",
      "91 0 24.690420150756836\n",
      "F1 Score on dev data: 0.00627\n",
      "92 0 24.59562110900879\n",
      "F1 Score on dev data: 0.00627\n",
      "93 0 24.50202751159668\n",
      "F1 Score on dev data: 0.00627\n",
      "94 0 24.40960693359375\n",
      "F1 Score on dev data: 0.00627\n",
      "95 0 24.318326950073242\n",
      "F1 Score on dev data: 0.00627\n",
      "96 0 24.228158950805664\n",
      "F1 Score on dev data: 0.00627\n",
      "97 0 24.13908576965332\n",
      "F1 Score on dev data: 0.00627\n",
      "98 0 24.05108070373535\n",
      "F1 Score on dev data: 0.00627\n",
      "99 0 23.964122772216797\n",
      "F1 Score on dev data: 0.00627\n",
      "100 0 23.87818717956543\n",
      "F1 Score on dev data: 0.00627\n",
      "101 0 23.793249130249023\n",
      "F1 Score on dev data: 0.00627\n",
      "102 0 23.709280014038086\n",
      "F1 Score on dev data: 0.00627\n",
      "103 0 23.62624168395996\n",
      "F1 Score on dev data: 0.00627\n",
      "104 0 23.54410743713379\n",
      "F1 Score on dev data: 0.00627\n",
      "105 0 23.46284294128418\n",
      "F1 Score on dev data: 0.00627\n",
      "106 0 23.38240623474121\n",
      "F1 Score on dev data: 0.00627\n",
      "107 0 23.302762985229492\n",
      "F1 Score on dev data: 0.00627\n",
      "108 0 23.223873138427734\n",
      "F1 Score on dev data: 0.00627\n",
      "109 0 23.145706176757812\n",
      "F1 Score on dev data: 0.00627\n",
      "110 0 23.068220138549805\n",
      "F1 Score on dev data: 0.00471\n",
      "111 0 22.99138832092285\n",
      "F1 Score on dev data: 0.00471\n",
      "112 0 22.9151668548584\n",
      "F1 Score on dev data: 0.00471\n",
      "113 0 22.83953285217285\n",
      "F1 Score on dev data: 0.00471\n",
      "114 0 22.764450073242188\n",
      "F1 Score on dev data: 0.00471\n",
      "115 0 22.68988800048828\n",
      "F1 Score on dev data: 0.00471\n",
      "116 0 22.615814208984375\n",
      "F1 Score on dev data: 0.00471\n",
      "117 0 22.542198181152344\n",
      "F1 Score on dev data: 0.00471\n",
      "118 0 22.46900749206543\n",
      "F1 Score on dev data: 0.00471\n",
      "119 0 22.396211624145508\n",
      "F1 Score on dev data: 0.00471\n",
      "120 0 22.323780059814453\n",
      "F1 Score on dev data: 0.00471\n",
      "121 0 22.25167465209961\n",
      "F1 Score on dev data: 0.00471\n",
      "122 0 22.17986488342285\n",
      "F1 Score on dev data: 0.00471\n",
      "123 0 22.10832405090332\n",
      "F1 Score on dev data: 0.00471\n",
      "124 0 22.037015914916992\n",
      "F1 Score on dev data: 0.00471\n",
      "125 0 21.965917587280273\n",
      "F1 Score on dev data: 0.00471\n",
      "126 0 21.895002365112305\n",
      "F1 Score on dev data: 0.00471\n",
      "127 0 21.82423973083496\n",
      "F1 Score on dev data: 0.00471\n",
      "128 0 21.75360870361328\n",
      "F1 Score on dev data: 0.00471\n",
      "129 0 21.683090209960938\n",
      "F1 Score on dev data: 0.00471\n",
      "130 0 21.612661361694336\n",
      "F1 Score on dev data: 0.00471\n",
      "131 0 21.542314529418945\n",
      "F1 Score on dev data: 0.00471\n",
      "132 0 21.472028732299805\n",
      "F1 Score on dev data: 0.00471\n",
      "133 0 21.401790618896484\n",
      "F1 Score on dev data: 0.00471\n",
      "134 0 21.331588745117188\n",
      "F1 Score on dev data: 0.00471\n",
      "135 0 21.261417388916016\n",
      "F1 Score on dev data: 0.00471\n",
      "136 0 21.191261291503906\n",
      "F1 Score on dev data: 0.00471\n",
      "137 0 21.121118545532227\n",
      "F1 Score on dev data: 0.00471\n",
      "138 0 21.050975799560547\n",
      "F1 Score on dev data: 0.00471\n",
      "139 0 20.980825424194336\n",
      "F1 Score on dev data: 0.00471\n",
      "140 0 20.91065788269043\n",
      "F1 Score on dev data: 0.00471\n",
      "141 0 20.84046173095703\n",
      "F1 Score on dev data: 0.00471\n",
      "142 0 20.77022933959961\n",
      "F1 Score on dev data: 0.00471\n",
      "143 0 20.69994354248047\n",
      "F1 Score on dev data: 0.00471\n",
      "144 0 20.629596710205078\n",
      "F1 Score on dev data: 0.00471\n",
      "145 0 20.559171676635742\n",
      "F1 Score on dev data: 0.00471\n",
      "146 0 20.488651275634766\n",
      "F1 Score on dev data: 0.00471\n",
      "147 0 20.418020248413086\n",
      "F1 Score on dev data: 0.00471\n",
      "148 0 20.347265243530273\n",
      "F1 Score on dev data: 0.00471\n",
      "149 0 20.276363372802734\n",
      "F1 Score on dev data: 0.00471\n",
      "150 0 20.20530128479004\n",
      "F1 Score on dev data: 0.00471\n",
      "151 0 20.13405418395996\n",
      "F1 Score on dev data: 0.00471\n",
      "152 0 20.062612533569336\n",
      "F1 Score on dev data: 0.00471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 0 19.990949630737305\n",
      "F1 Score on dev data: 0.00471\n",
      "154 0 19.919055938720703\n",
      "F1 Score on dev data: 0.00471\n",
      "155 0 19.84691047668457\n",
      "F1 Score on dev data: 0.00471\n",
      "156 0 19.77449607849121\n",
      "F1 Score on dev data: 0.00471\n",
      "157 0 19.701801300048828\n",
      "F1 Score on dev data: 0.00471\n",
      "158 0 19.62881088256836\n",
      "F1 Score on dev data: 0.00471\n",
      "159 0 19.555509567260742\n",
      "F1 Score on dev data: 0.00471\n",
      "160 0 19.481889724731445\n",
      "F1 Score on dev data: 0.00471\n",
      "161 0 19.40793228149414\n",
      "F1 Score on dev data: 0.00471\n",
      "162 0 19.33363151550293\n",
      "F1 Score on dev data: 0.00471\n",
      "163 0 19.25897216796875\n",
      "F1 Score on dev data: 0.00471\n",
      "164 0 19.18393898010254\n",
      "F1 Score on dev data: 0.00471\n",
      "165 0 19.1085262298584\n",
      "F1 Score on dev data: 0.00471\n",
      "166 0 19.03272247314453\n",
      "F1 Score on dev data: 0.00471\n",
      "167 0 18.956506729125977\n",
      "F1 Score on dev data: 0.00471\n",
      "168 0 18.8798770904541\n",
      "F1 Score on dev data: 0.00471\n",
      "169 0 18.80281639099121\n",
      "F1 Score on dev data: 0.00471\n",
      "170 0 18.725313186645508\n",
      "F1 Score on dev data: 0.00471\n",
      "171 0 18.647357940673828\n",
      "F1 Score on dev data: 0.00471\n",
      "172 0 18.568939208984375\n",
      "F1 Score on dev data: 0.00471\n",
      "173 0 18.490047454833984\n",
      "F1 Score on dev data: 0.00471\n",
      "174 0 18.410669326782227\n",
      "F1 Score on dev data: 0.00471\n",
      "175 0 18.330795288085938\n",
      "F1 Score on dev data: 0.00471\n",
      "176 0 18.25042152404785\n",
      "F1 Score on dev data: 0.00471\n",
      "177 0 18.169532775878906\n",
      "F1 Score on dev data: 0.00471\n",
      "178 0 18.088119506835938\n",
      "F1 Score on dev data: 0.00471\n",
      "179 0 18.006175994873047\n",
      "F1 Score on dev data: 0.00471\n",
      "180 0 17.923690795898438\n",
      "F1 Score on dev data: 0.00471\n",
      "181 0 17.840660095214844\n",
      "F1 Score on dev data: 0.00471\n",
      "182 0 17.757070541381836\n",
      "F1 Score on dev data: 0.00471\n",
      "183 0 17.67291831970215\n",
      "F1 Score on dev data: 0.00627\n",
      "184 0 17.58819007873535\n",
      "F1 Score on dev data: 0.00627\n",
      "185 0 17.502883911132812\n",
      "F1 Score on dev data: 0.00627\n",
      "186 0 17.416994094848633\n",
      "F1 Score on dev data: 0.00627\n",
      "187 0 17.330507278442383\n",
      "F1 Score on dev data: 0.00627\n",
      "188 0 17.243425369262695\n",
      "F1 Score on dev data: 0.00627\n",
      "189 0 17.155736923217773\n",
      "F1 Score on dev data: 0.00627\n",
      "190 0 17.067445755004883\n",
      "F1 Score on dev data: 0.00627\n",
      "191 0 16.97854232788086\n",
      "F1 Score on dev data: 0.00627\n",
      "192 0 16.88902473449707\n",
      "F1 Score on dev data: 0.00627\n",
      "193 0 16.798892974853516\n",
      "F1 Score on dev data: 0.00627\n",
      "194 0 16.708141326904297\n",
      "F1 Score on dev data: 0.00627\n",
      "195 0 16.616771697998047\n",
      "F1 Score on dev data: 0.00627\n",
      "196 0 16.524782180786133\n",
      "F1 Score on dev data: 0.00627\n",
      "197 0 16.432178497314453\n",
      "F1 Score on dev data: 0.00627\n",
      "198 0 16.338953018188477\n",
      "F1 Score on dev data: 0.00627\n",
      "199 0 16.24510955810547\n",
      "F1 Score on dev data: 0.00627\n",
      "200 0 16.150653839111328\n",
      "F1 Score on dev data: 0.00627\n",
      "201 0 16.055583953857422\n",
      "F1 Score on dev data: 0.00627\n",
      "202 0 15.959906578063965\n",
      "F1 Score on dev data: 0.00627\n",
      "203 0 15.863617897033691\n",
      "F1 Score on dev data: 0.00627\n",
      "204 0 15.76672649383545\n",
      "F1 Score on dev data: 0.00627\n",
      "205 0 15.66923713684082\n",
      "F1 Score on dev data: 0.00627\n",
      "206 0 15.57115364074707\n",
      "F1 Score on dev data: 0.00627\n",
      "207 0 15.472480773925781\n",
      "F1 Score on dev data: 0.00627\n",
      "208 0 15.373225212097168\n",
      "F1 Score on dev data: 0.00784\n",
      "209 0 15.273391723632812\n",
      "F1 Score on dev data: 0.00784\n",
      "210 0 15.172987937927246\n",
      "F1 Score on dev data: 0.00784\n",
      "211 0 15.072023391723633\n",
      "F1 Score on dev data: 0.00784\n",
      "212 0 14.970503807067871\n",
      "F1 Score on dev data: 0.00784\n",
      "213 0 14.868439674377441\n",
      "F1 Score on dev data: 0.00941\n",
      "214 0 14.765840530395508\n",
      "F1 Score on dev data: 0.00941\n",
      "215 0 14.662717819213867\n",
      "F1 Score on dev data: 0.01098\n",
      "216 0 14.559082984924316\n",
      "F1 Score on dev data: 0.01098\n",
      "217 0 14.454951286315918\n",
      "F1 Score on dev data: 0.01098\n",
      "218 0 14.350334167480469\n",
      "F1 Score on dev data: 0.01098\n",
      "219 0 14.245248794555664\n",
      "F1 Score on dev data: 0.01098\n",
      "220 0 14.139713287353516\n",
      "F1 Score on dev data: 0.01255\n",
      "221 0 14.033746719360352\n",
      "F1 Score on dev data: 0.01255\n",
      "222 0 13.927367210388184\n",
      "F1 Score on dev data: 0.01255\n",
      "223 0 13.820598602294922\n",
      "F1 Score on dev data: 0.01412\n",
      "224 0 13.71346378326416\n",
      "F1 Score on dev data: 0.01412\n",
      "225 0 13.605986595153809\n",
      "F1 Score on dev data: 0.01412\n",
      "226 0 13.498194694519043\n",
      "F1 Score on dev data: 0.01412\n",
      "227 0 13.390117645263672\n",
      "F1 Score on dev data: 0.01412\n",
      "228 0 13.281781196594238\n",
      "F1 Score on dev data: 0.01412\n",
      "229 0 13.173219680786133\n",
      "F1 Score on dev data: 0.01412\n",
      "230 0 13.064467430114746\n",
      "F1 Score on dev data: 0.01412\n",
      "231 0 12.955554008483887\n",
      "F1 Score on dev data: 0.01412\n",
      "232 0 12.846518516540527\n",
      "F1 Score on dev data: 0.01412\n",
      "233 0 12.737399101257324\n",
      "F1 Score on dev data: 0.01412\n",
      "234 0 12.628232955932617\n",
      "F1 Score on dev data: 0.01412\n",
      "235 0 12.519060134887695\n",
      "F1 Score on dev data: 0.01412\n",
      "236 0 12.409923553466797\n",
      "F1 Score on dev data: 0.01412\n",
      "237 0 12.300864219665527\n",
      "F1 Score on dev data: 0.01725\n",
      "238 0 12.19192886352539\n",
      "F1 Score on dev data: 0.02039\n",
      "239 0 12.083158493041992\n",
      "F1 Score on dev data: 0.02039\n",
      "240 0 11.974601745605469\n",
      "F1 Score on dev data: 0.02039\n",
      "241 0 11.866305351257324\n",
      "F1 Score on dev data: 0.02196\n",
      "242 0 11.758318901062012\n",
      "F1 Score on dev data: 0.02353\n",
      "243 0 11.650693893432617\n",
      "F1 Score on dev data: 0.02353\n",
      "244 0 11.543482780456543\n",
      "F1 Score on dev data: 0.02353\n",
      "245 0 11.436739921569824\n",
      "F1 Score on dev data: 0.02353\n",
      "246 0 11.330521583557129\n",
      "F1 Score on dev data: 0.02510\n",
      "247 0 11.224891662597656\n",
      "F1 Score on dev data: 0.02510\n",
      "248 0 11.11990737915039\n",
      "F1 Score on dev data: 0.02510\n",
      "249 0 11.01563549041748\n",
      "F1 Score on dev data: 0.02510\n",
      "250 0 10.912138938903809\n",
      "F1 Score on dev data: 0.02510\n",
      "251 0 10.80948543548584\n",
      "F1 Score on dev data: 0.02667\n",
      "252 0 10.707742691040039\n",
      "F1 Score on dev data: 0.02980\n",
      "253 0 10.606973648071289\n",
      "F1 Score on dev data: 0.02980\n",
      "254 0 10.507243156433105\n",
      "F1 Score on dev data: 0.02980\n",
      "255 0 10.408614158630371\n",
      "F1 Score on dev data: 0.02980\n",
      "256 0 10.311144828796387\n",
      "F1 Score on dev data: 0.02980\n",
      "257 0 10.214888572692871\n",
      "F1 Score on dev data: 0.03294\n",
      "258 0 10.119893074035645\n",
      "F1 Score on dev data: 0.03294\n",
      "259 0 10.026199340820312\n",
      "F1 Score on dev data: 0.03451\n",
      "260 0 9.933845520019531\n",
      "F1 Score on dev data: 0.03451\n",
      "261 0 9.84285831451416\n",
      "F1 Score on dev data: 0.03451\n",
      "262 0 9.753263473510742\n",
      "F1 Score on dev data: 0.03608\n",
      "263 0 9.665077209472656\n",
      "F1 Score on dev data: 0.03765\n",
      "264 0 9.578309059143066\n",
      "F1 Score on dev data: 0.03922\n",
      "265 0 9.49296760559082\n",
      "F1 Score on dev data: 0.04078\n",
      "266 0 9.409050941467285\n",
      "F1 Score on dev data: 0.04392\n",
      "267 0 9.32656192779541\n",
      "F1 Score on dev data: 0.04392\n",
      "268 0 9.245494842529297\n",
      "F1 Score on dev data: 0.05020\n",
      "269 0 9.165843963623047\n",
      "F1 Score on dev data: 0.05020\n",
      "270 0 9.087600708007812\n",
      "F1 Score on dev data: 0.05176\n",
      "271 0 9.010760307312012\n",
      "F1 Score on dev data: 0.05490\n",
      "272 0 8.93531322479248\n",
      "F1 Score on dev data: 0.05490\n",
      "273 0 8.861257553100586\n",
      "F1 Score on dev data: 0.05647\n",
      "274 0 8.788586616516113\n",
      "F1 Score on dev data: 0.05804\n",
      "275 0 8.717301368713379\n",
      "F1 Score on dev data: 0.05961\n",
      "276 0 8.647403717041016\n",
      "F1 Score on dev data: 0.05961\n",
      "277 0 8.578895568847656\n",
      "F1 Score on dev data: 0.06118\n",
      "278 0 8.511785507202148\n",
      "F1 Score on dev data: 0.06118\n",
      "279 0 8.446080207824707\n",
      "F1 Score on dev data: 0.06118\n",
      "280 0 8.381786346435547\n",
      "F1 Score on dev data: 0.06118\n",
      "281 0 8.318914413452148\n",
      "F1 Score on dev data: 0.06275\n",
      "282 0 8.257468223571777\n",
      "F1 Score on dev data: 0.06431\n",
      "283 0 8.197452545166016\n",
      "F1 Score on dev data: 0.06588\n",
      "284 0 8.138869285583496\n",
      "F1 Score on dev data: 0.06588\n",
      "285 0 8.081713676452637\n",
      "F1 Score on dev data: 0.06902\n",
      "286 0 8.025979042053223\n",
      "F1 Score on dev data: 0.07059\n",
      "287 0 7.971652507781982\n",
      "F1 Score on dev data: 0.07059\n",
      "288 0 7.918715000152588\n",
      "F1 Score on dev data: 0.07059\n",
      "289 0 7.86714506149292\n",
      "F1 Score on dev data: 0.07373\n",
      "290 0 7.81691312789917\n",
      "F1 Score on dev data: 0.07529\n",
      "291 0 7.767990589141846\n",
      "F1 Score on dev data: 0.07843\n",
      "292 0 7.720340728759766\n",
      "F1 Score on dev data: 0.07843\n",
      "293 0 7.673924446105957\n",
      "F1 Score on dev data: 0.08000\n",
      "294 0 7.6287007331848145\n",
      "F1 Score on dev data: 0.08000\n",
      "295 0 7.584628105163574\n",
      "F1 Score on dev data: 0.08000\n",
      "296 0 7.541661262512207\n",
      "F1 Score on dev data: 0.08314\n",
      "297 0 7.499756336212158\n",
      "F1 Score on dev data: 0.08471\n",
      "298 0 7.458868026733398\n",
      "F1 Score on dev data: 0.08471\n",
      "299 0 7.4189534187316895\n",
      "F1 Score on dev data: 0.08941\n",
      "300 0 7.379968643188477\n",
      "F1 Score on dev data: 0.09098\n",
      "301 0 7.341872215270996\n",
      "F1 Score on dev data: 0.09098\n",
      "302 0 7.304623603820801\n",
      "F1 Score on dev data: 0.09098\n",
      "303 0 7.268187046051025\n",
      "F1 Score on dev data: 0.09098\n",
      "304 0 7.232525825500488\n",
      "F1 Score on dev data: 0.09098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305 0 7.19760799407959\n",
      "F1 Score on dev data: 0.09098\n",
      "306 0 7.163403034210205\n",
      "F1 Score on dev data: 0.09412\n",
      "307 0 7.129883289337158\n",
      "F1 Score on dev data: 0.09412\n",
      "308 0 7.0970234870910645\n",
      "F1 Score on dev data: 0.09569\n",
      "309 0 7.064802169799805\n",
      "F1 Score on dev data: 0.09725\n",
      "310 0 7.03319787979126\n",
      "F1 Score on dev data: 0.09725\n",
      "311 0 7.002192974090576\n",
      "F1 Score on dev data: 0.09882\n",
      "312 0 6.97177267074585\n",
      "F1 Score on dev data: 0.10039\n",
      "313 0 6.941921710968018\n",
      "F1 Score on dev data: 0.10196\n",
      "314 0 6.912627696990967\n",
      "F1 Score on dev data: 0.10196\n",
      "315 0 6.883881568908691\n",
      "F1 Score on dev data: 0.10196\n",
      "316 0 6.855671405792236\n",
      "F1 Score on dev data: 0.10196\n",
      "317 0 6.827991485595703\n",
      "F1 Score on dev data: 0.10353\n",
      "318 0 6.800830364227295\n",
      "F1 Score on dev data: 0.10353\n",
      "319 0 6.774185657501221\n",
      "F1 Score on dev data: 0.10667\n",
      "320 0 6.748048305511475\n",
      "F1 Score on dev data: 0.10667\n",
      "321 0 6.722413539886475\n",
      "F1 Score on dev data: 0.10667\n",
      "322 0 6.697274684906006\n",
      "F1 Score on dev data: 0.10824\n",
      "323 0 6.672626495361328\n",
      "F1 Score on dev data: 0.10824\n",
      "324 0 6.648462772369385\n",
      "F1 Score on dev data: 0.10824\n",
      "325 0 6.624779224395752\n",
      "F1 Score on dev data: 0.10824\n",
      "326 0 6.601569652557373\n",
      "F1 Score on dev data: 0.10824\n",
      "327 0 6.57882833480835\n",
      "F1 Score on dev data: 0.10824\n",
      "328 0 6.556547164916992\n",
      "F1 Score on dev data: 0.10824\n",
      "329 0 6.534723281860352\n",
      "F1 Score on dev data: 0.10824\n",
      "330 0 6.513348579406738\n",
      "F1 Score on dev data: 0.10824\n",
      "331 0 6.492416858673096\n",
      "F1 Score on dev data: 0.10824\n",
      "332 0 6.471921920776367\n",
      "F1 Score on dev data: 0.11137\n",
      "333 0 6.451857089996338\n",
      "F1 Score on dev data: 0.11137\n",
      "334 0 6.432215690612793\n",
      "F1 Score on dev data: 0.11137\n",
      "335 0 6.412991046905518\n",
      "F1 Score on dev data: 0.11137\n",
      "336 0 6.394176483154297\n",
      "F1 Score on dev data: 0.11451\n",
      "337 0 6.375765800476074\n",
      "F1 Score on dev data: 0.11608\n",
      "338 0 6.357752323150635\n",
      "F1 Score on dev data: 0.11765\n",
      "339 0 6.340128421783447\n",
      "F1 Score on dev data: 0.11765\n",
      "340 0 6.322890281677246\n",
      "F1 Score on dev data: 0.11765\n",
      "341 0 6.306028842926025\n",
      "F1 Score on dev data: 0.11765\n",
      "342 0 6.289539813995361\n",
      "F1 Score on dev data: 0.11765\n",
      "343 0 6.273416042327881\n",
      "F1 Score on dev data: 0.11765\n",
      "344 0 6.2576518058776855\n",
      "F1 Score on dev data: 0.11922\n",
      "345 0 6.242241382598877\n",
      "F1 Score on dev data: 0.11922\n",
      "346 0 6.227177619934082\n",
      "F1 Score on dev data: 0.11922\n",
      "347 0 6.212456703186035\n",
      "F1 Score on dev data: 0.11922\n",
      "348 0 6.198070049285889\n",
      "F1 Score on dev data: 0.11922\n",
      "349 0 6.184014320373535\n",
      "F1 Score on dev data: 0.11922\n",
      "350 0 6.170282363891602\n",
      "F1 Score on dev data: 0.11922\n",
      "351 0 6.156867980957031\n",
      "F1 Score on dev data: 0.11922\n",
      "352 0 6.143766403198242\n",
      "F1 Score on dev data: 0.11922\n",
      "353 0 6.1309709548950195\n",
      "F1 Score on dev data: 0.11922\n",
      "354 0 6.118475914001465\n",
      "F1 Score on dev data: 0.11922\n",
      "355 0 6.106276035308838\n",
      "F1 Score on dev data: 0.11922\n",
      "356 0 6.094366073608398\n",
      "F1 Score on dev data: 0.11922\n",
      "357 0 6.082740783691406\n",
      "F1 Score on dev data: 0.11922\n",
      "358 0 6.071393966674805\n",
      "F1 Score on dev data: 0.11922\n",
      "359 0 6.060319423675537\n",
      "F1 Score on dev data: 0.11922\n",
      "360 0 6.0495147705078125\n",
      "F1 Score on dev data: 0.11922\n",
      "361 0 6.038972854614258\n",
      "F1 Score on dev data: 0.11922\n",
      "362 0 6.028690338134766\n",
      "F1 Score on dev data: 0.12078\n",
      "363 0 6.018660545349121\n",
      "F1 Score on dev data: 0.12078\n",
      "364 0 6.0088791847229\n",
      "F1 Score on dev data: 0.12078\n",
      "365 0 5.999343395233154\n",
      "F1 Score on dev data: 0.12078\n",
      "366 0 5.990046977996826\n",
      "F1 Score on dev data: 0.12078\n",
      "367 0 5.98098611831665\n",
      "F1 Score on dev data: 0.12078\n",
      "368 0 5.972157001495361\n",
      "F1 Score on dev data: 0.12078\n",
      "369 0 5.9635539054870605\n",
      "F1 Score on dev data: 0.12078\n",
      "370 0 5.955173492431641\n",
      "F1 Score on dev data: 0.12078\n",
      "371 0 5.9470109939575195\n",
      "F1 Score on dev data: 0.12078\n",
      "372 0 5.939062118530273\n",
      "F1 Score on dev data: 0.12078\n",
      "373 0 5.93132209777832\n",
      "F1 Score on dev data: 0.12235\n",
      "374 0 5.923789024353027\n",
      "F1 Score on dev data: 0.12235\n",
      "375 0 5.91645622253418\n",
      "F1 Score on dev data: 0.12235\n",
      "376 0 5.909320831298828\n",
      "F1 Score on dev data: 0.12235\n",
      "377 0 5.902378082275391\n",
      "F1 Score on dev data: 0.12235\n",
      "378 0 5.895623207092285\n",
      "F1 Score on dev data: 0.12235\n",
      "379 0 5.889054298400879\n",
      "F1 Score on dev data: 0.12235\n",
      "380 0 5.882667064666748\n",
      "F1 Score on dev data: 0.12235\n",
      "381 0 5.8764567375183105\n",
      "F1 Score on dev data: 0.12235\n",
      "382 0 5.870420932769775\n",
      "F1 Score on dev data: 0.12235\n",
      "383 0 5.864555835723877\n",
      "F1 Score on dev data: 0.12235\n",
      "384 0 5.858857154846191\n",
      "F1 Score on dev data: 0.12235\n",
      "385 0 5.8533244132995605\n",
      "F1 Score on dev data: 0.12235\n",
      "386 0 5.847951412200928\n",
      "F1 Score on dev data: 0.12235\n",
      "387 0 5.842739105224609\n",
      "F1 Score on dev data: 0.12235\n",
      "388 0 5.837681770324707\n",
      "F1 Score on dev data: 0.12235\n",
      "389 0 5.8327789306640625\n",
      "F1 Score on dev data: 0.12235\n",
      "390 0 5.828025817871094\n",
      "F1 Score on dev data: 0.12235\n",
      "391 0 5.823422431945801\n",
      "F1 Score on dev data: 0.12235\n",
      "392 0 5.818966865539551\n",
      "F1 Score on dev data: 0.12235\n",
      "393 0 5.81465482711792\n",
      "F1 Score on dev data: 0.12235\n",
      "394 0 5.810486316680908\n",
      "F1 Score on dev data: 0.12235\n",
      "395 0 5.806458950042725\n",
      "F1 Score on dev data: 0.12235\n",
      "396 0 5.802570343017578\n",
      "F1 Score on dev data: 0.12549\n",
      "397 0 5.7988200187683105\n",
      "F1 Score on dev data: 0.12549\n",
      "398 0 5.795205116271973\n",
      "F1 Score on dev data: 0.12392\n",
      "399 0 5.791726112365723\n",
      "F1 Score on dev data: 0.12392\n",
      "400 0 5.788379669189453\n",
      "F1 Score on dev data: 0.12392\n",
      "401 0 5.785165309906006\n",
      "F1 Score on dev data: 0.12392\n",
      "402 0 5.782081604003906\n",
      "F1 Score on dev data: 0.12392\n",
      "403 0 5.7791266441345215\n",
      "F1 Score on dev data: 0.12392\n",
      "404 0 5.776299953460693\n",
      "F1 Score on dev data: 0.12235\n",
      "405 0 5.773601531982422\n",
      "F1 Score on dev data: 0.12235\n",
      "406 0 5.7710280418396\n",
      "F1 Score on dev data: 0.12235\n",
      "407 0 5.768579006195068\n",
      "F1 Score on dev data: 0.12235\n",
      "408 0 5.766254425048828\n",
      "F1 Score on dev data: 0.12392\n",
      "409 0 5.764051914215088\n",
      "F1 Score on dev data: 0.12549\n",
      "410 0 5.761972904205322\n",
      "F1 Score on dev data: 0.12549\n",
      "411 0 5.760013580322266\n",
      "F1 Score on dev data: 0.12392\n",
      "412 0 5.758174896240234\n",
      "F1 Score on dev data: 0.12392\n",
      "413 0 5.756455421447754\n",
      "F1 Score on dev data: 0.12392\n",
      "414 0 5.754853248596191\n",
      "F1 Score on dev data: 0.12392\n",
      "415 0 5.753368854522705\n",
      "F1 Score on dev data: 0.12392\n",
      "416 0 5.7520012855529785\n",
      "F1 Score on dev data: 0.12392\n",
      "417 0 5.750749111175537\n",
      "F1 Score on dev data: 0.12392\n",
      "418 0 5.749611854553223\n",
      "F1 Score on dev data: 0.12392\n",
      "419 0 5.7485880851745605\n",
      "F1 Score on dev data: 0.12392\n",
      "420 0 5.747676372528076\n",
      "F1 Score on dev data: 0.12392\n",
      "421 0 5.746874809265137\n",
      "F1 Score on dev data: 0.12392\n",
      "422 0 5.7461838722229\n",
      "F1 Score on dev data: 0.12392\n",
      "423 0 5.745603561401367\n",
      "F1 Score on dev data: 0.12392\n",
      "424 0 5.74513053894043\n",
      "F1 Score on dev data: 0.12392\n",
      "425 0 5.744762897491455\n",
      "F1 Score on dev data: 0.12392\n",
      "426 0 5.74450159072876\n",
      "F1 Score on dev data: 0.12392\n",
      "427 0 5.744344711303711\n",
      "F1 Score on dev data: 0.12392\n",
      "428 0 5.744290351867676\n",
      "F1 Score on dev data: 0.12235\n",
      "429 0 5.744338035583496\n",
      "F1 Score on dev data: 0.12235\n"
     ]
    }
   ],
   "source": [
    "if(is_train):\n",
    "    dev_input, dev_target = get_batch_data(train_size, data_size)\n",
    "    train(net, optimizer, reg_lambda, max_epochs, dev_input, dev_target, batch_size, train_size)\n",
    "\n",
    "    torch.save(net.weights, WEIGHTS_PATH + 'skipgram_weights_' + str(vocab_size) + '.pt')\n",
    "    torch.save(net.biases, WEIGHTS_PATH + 'skipgram_biases_' + str(vocab_size) + '.pt')\n",
    "else:\n",
    "    net.weights = torch.load(WEIGHTS_PATH + 'skipgram_weights_' + str(vocab_size) + '.pt')\n",
    "    net.biases = torch.load(WEIGHTS_PATH + 'skipgram_biases_' + str(vocab_size) + '.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6840339",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "01659421",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 991/991 [00:01<00:00, 558.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 991/991 [00:00<00:00, 115620.45it/s]\n"
     ]
    }
   ],
   "source": [
    "validation = pd.read_csv(VALIDATION, sep=' ', names=['word1','word2','word3','word4'])\n",
    "\n",
    "validation['word1'] = validation['word1'].apply(lambda x : x.lower())\n",
    "validation['word2'] = validation['word2'].apply(lambda x : x.lower())\n",
    "validation['word3'] = validation['word3'].apply(lambda x : x.lower())\n",
    "validation['word4'] = validation['word4'].apply(lambda x : x.lower())\n",
    "\n",
    "validation['pred'] = validation[['word1','word2','word3']].progress_apply(lambda x : get_result(x['word1'], x['word2'], x['word3'], problem=problem, window=10), axis = 1)\n",
    "validation['found'] = validation[['word4','pred']].progress_apply(lambda x : x['word4'] in x['pred'], axis=1)\n",
    "\n",
    "# count = len(os.listdir(RESULTS_PATH))\n",
    "# validation.to_csv(RESULTS_PATH + \"value_\"+str(count)+'_'+str(vocab_size)+'_'+str(no_of_rows)+problem+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e9c1d950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>word3</th>\n",
       "      <th>word4</th>\n",
       "      <th>pred</th>\n",
       "      <th>found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>walk</td>\n",
       "      <td>walks</td>\n",
       "      <td>see</td>\n",
       "      <td>sees</td>\n",
       "      <td>[is, sees, walking, wife, japan, lower, mango,...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>walk</td>\n",
       "      <td>walks</td>\n",
       "      <td>shuffle</td>\n",
       "      <td>shuffles</td>\n",
       "      <td>[is, shuffles, Bangkok, wife, shuffling, spend...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>walk</td>\n",
       "      <td>walks</td>\n",
       "      <td>sing</td>\n",
       "      <td>sings</td>\n",
       "      <td>[is, sings, Senegal, singing, wife, Guinea, bi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>walk</td>\n",
       "      <td>walks</td>\n",
       "      <td>sit</td>\n",
       "      <td>sits</td>\n",
       "      <td>[is, sitting, walking, shuffles, sits, wife, b...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>walk</td>\n",
       "      <td>walks</td>\n",
       "      <td>speak</td>\n",
       "      <td>speaks</td>\n",
       "      <td>[is, walking, harder, wife, think, spending, s...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>algeria</td>\n",
       "      <td>dinar</td>\n",
       "      <td>iran</td>\n",
       "      <td>rial</td>\n",
       "      <td>[is, dinar, israeli, rial, possibly, India, de...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>argentina</td>\n",
       "      <td>peso</td>\n",
       "      <td>usa</td>\n",
       "      <td>dollar</td>\n",
       "      <td>[is, peso, dollar, stepmother, France, finds, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>argentina</td>\n",
       "      <td>peso</td>\n",
       "      <td>nigeria</td>\n",
       "      <td>naira</td>\n",
       "      <td>[is, peso, naira, finds, unethical, warm, Fran...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>argentina</td>\n",
       "      <td>peso</td>\n",
       "      <td>iran</td>\n",
       "      <td>rial</td>\n",
       "      <td>[is, peso, rial, France, cool, Norwegian, swed...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>india</td>\n",
       "      <td>rupee</td>\n",
       "      <td>iran</td>\n",
       "      <td>rial</td>\n",
       "      <td>[easy, rial, young, kerala, sat, denmark, is, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>551 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word1  word2    word3     word4  \\\n",
       "0         walk  walks      see      sees   \n",
       "1         walk  walks  shuffle  shuffles   \n",
       "2         walk  walks     sing     sings   \n",
       "3         walk  walks      sit      sits   \n",
       "5         walk  walks    speak    speaks   \n",
       "..         ...    ...      ...       ...   \n",
       "983    algeria  dinar     iran      rial   \n",
       "985  argentina   peso      usa    dollar   \n",
       "986  argentina   peso  nigeria     naira   \n",
       "987  argentina   peso     iran      rial   \n",
       "989      india  rupee     iran      rial   \n",
       "\n",
       "                                                  pred  found  \n",
       "0    [is, sees, walking, wife, japan, lower, mango,...   True  \n",
       "1    [is, shuffles, Bangkok, wife, shuffling, spend...   True  \n",
       "2    [is, sings, Senegal, singing, wife, Guinea, bi...   True  \n",
       "3    [is, sitting, walking, shuffles, sits, wife, b...   True  \n",
       "5    [is, walking, harder, wife, think, spending, s...   True  \n",
       "..                                                 ...    ...  \n",
       "983  [is, dinar, israeli, rial, possibly, India, de...   True  \n",
       "985  [is, peso, dollar, stepmother, France, finds, ...   True  \n",
       "986  [is, peso, naira, finds, unethical, warm, Fran...   True  \n",
       "987  [is, peso, rial, France, cool, Norwegian, swed...   True  \n",
       "989  [easy, rial, young, kerala, sat, denmark, is, ...   True  \n",
       "\n",
       "[551 rows x 6 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation[validation['found']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8b9a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = validation[validation['found']==False].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "902e55a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[['word1','word2','word3','word4']]\n",
    "x.to_csv(\"addition.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b393bd",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "782f0b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plays', 'is', 'flying', 'certain', 'groom']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "get_result('run','ran','play', problem='skipgram', window=5)\n",
    "\n",
    "# get_similarity('queen', 'woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4533003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8afdc823",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccca656",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = list(range(len(epochs_stat)))\n",
    "total_loss = []\n",
    "for i in range(len(epochs_stat)):\n",
    "    total_loss.append(sum(epochs_stat[i]['losses'])/len(epochs_stat[i]['losses']))\n",
    "    \n",
    "plot_loss_vs_batch(epochs, total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9630a95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f1_vs_epoch(epochs,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc0b6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_f1_vs_epoch(batches, losses):\n",
    "    plt.figure()\n",
    "    plt.plot(batches, losses)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('F1 score')\n",
    "    plt.title('Fl score vs. Epochs on Dev data')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dc9ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss_vs_batch(batches, losses):\n",
    "    plt.figure()\n",
    "    plt.plot(batches, losses)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss vs. Epochs')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35e3c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the input list\n",
    "input_list = ['30k', '123k', '216k', '391k', '1579k']\n",
    "\n",
    "# Define the two lists to compare\n",
    "list1 = [35, 154, 387, 0, 0]\n",
    "list2 = [7, 19, 35, 68, 152]\n",
    "\n",
    "# Set the width of the bars\n",
    "barWidth = 0.35\n",
    "\n",
    "# Set the positions of the bars on the x-axis\n",
    "r1 = range(len(input_list))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "\n",
    "# Create the plot\n",
    "plt.bar(r1, list1, color='red', width=barWidth, edgecolor='white', label='time with np arrays(in min)')\n",
    "plt.bar(r2, list2, color='blue', width=barWidth, edgecolor='white', label='time with tensors(in min)')\n",
    "\n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('Sentences')\n",
    "plt.ylabel('Time for 10 epochs')\n",
    "plt.xticks([r + barWidth / 2 for r in r1], input_list)\n",
    "\n",
    "# Create a legend & show the plot\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccfb8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
